{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous Line Following Using JetBot\n",
    "` Inspired by and based on: RoboCupJunior Rescue Line â€“ Rules 2018`\n",
    "\n",
    "An autonomous robot should follow a black line while overcoming different problems in a\n",
    "modular Field formed by tiles with different patterns. The floor is white in color and the tiles are on\n",
    "different levels connected with ramps. The end of the field will be marked with a strip of reflective silver\n",
    "tape on the floor. Teams are not allowed to give their robot any advance information about the field as the\n",
    "robot is supposed to recognize the field by itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import threading\n",
    "import traitlets\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import asyncio\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create jetbot and camera instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported the ``Robot`` class we can initialize the class *instance* as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera has been Initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "##create robot instance\n",
    "robot = Robot()\n",
    "\n",
    "#creating camera instance \n",
    "camera = Camera()\n",
    "print('Camera has been Initialized successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01342a4ec1304890bb8bf023e98bc7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e35119ec73d42eda54b5a85a79c5cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9994013c7945b3a0c88f038c47e293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d2a06afa0b4e1da176ba3b9d15dcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f848276cf77410c9cc42fa2d8839e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='cx: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee9948784c841248d6e7bd757d7172b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='cy: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0286b5e086c549c8b604e5865e564d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Avg x: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759f7b60280e4359ae385ae0c83b8184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Avg y: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4781797da70342d690b0e8aad90fdcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Area: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "x, y, w, h = 50, 50, 100, 100\n",
    "\n",
    "turn_time = time.time() # current time \n",
    "\n",
    "# Create display widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "gray_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "green_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "red_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "cx_label = widgets.Label(value='cx: ')\n",
    "cy_label = widgets.Label(value='cy: ')\n",
    "average_x_label = widgets.Label(value='Avg x: ')\n",
    "average_y_label = widgets.Label(value='Avg y: ')\n",
    "area_label = widgets.Label(value= 'Area: ')\n",
    "\n",
    "# Display the widgets\n",
    "display(image_widget, gray_widget, green_widget,red_widget,cx_label,cy_label,average_x_label, average_y_label, area_label)\n",
    "\n",
    "\n",
    "# Function to convert BGR image to JPEG format\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "def filter_outliers(intersections, m=0.5):\n",
    "    if not intersections:\n",
    "        return []\n",
    "\n",
    "    # Convert the list of tuples to a numpy array for easier manipulation\n",
    "    intersection_points = np.array(intersections)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the points\n",
    "    mean = np.mean(intersection_points, axis=0)\n",
    "    std_dev = np.std(intersection_points, axis=0)\n",
    "    \n",
    "    # Calculate the z-score for each point (distance from the mean in terms of standard deviation)\n",
    "    z_scores = (intersection_points - mean) / std_dev\n",
    "    \n",
    "    # Filter the points where the absolute z-score is less than 'm' for both x and y\n",
    "    filtered_points = intersection_points[(np.abs(z_scores) < m).all(axis=1)]\n",
    "    \n",
    "    return filtered_points\n",
    "\n",
    "\n",
    "#function to find the intersection of the line \n",
    "def find_intersection(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Manually set the threshold value\n",
    "    manual_threshold_value = 70\n",
    "    # Apply manual thresholding\n",
    "    _, thresholded = cv2.threshold(gray, manual_threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "    canny_image=cv2.Canny(thresholded, 50, 150)\n",
    "    lines=cv2.HoughLinesP(canny_image, rho=1, theta=np.pi/180, threshold=45, minLineLength=10, maxLineGap=300)\n",
    "    \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(image, (x1, y1), (x2, y2),  (255, 0, 0), 1)\n",
    "    intersections = []\n",
    "    average_intersection = None\n",
    "    if lines is not None:\n",
    "        for i, line1 in enumerate(lines):\n",
    "            for line2 in lines[i+1:]:\n",
    "                x1, y1, x2, y2 = line1[0]\n",
    "                x3, y3, x4, y4 = line2[0]\n",
    "\n",
    "                # Line AB represented as a1x + b1y = c1\n",
    "                a1 = y2 - y1\n",
    "                b1 = x1 - x2\n",
    "                c1 = a1*x1 + b1*y1\n",
    "\n",
    "                # Line CD represented as a2x + b2y = c2\n",
    "                a2 = y4 - y3\n",
    "                b2 = x3 - x4\n",
    "                c2 = a2*x3 + b2*y3\n",
    "\n",
    "                determinant = a1*b2 - a2*b1\n",
    "\n",
    "                if determinant != 0:\n",
    "                    x = (b2*c1 - b1*c2) / determinant\n",
    "                    y = (a1*c2 - a2*c1) / determinant\n",
    "                    \n",
    "                    intersections.append((int(x), int(y)))\n",
    "                    \n",
    "        intersections = filter_outliers(intersections)\n",
    "        \n",
    "        if len(intersections) > 0: \n",
    "            average_x = sum(x for x, y in intersections) / len(intersections)\n",
    "            average_y = sum(y for x, y in intersections) / len(intersections)\n",
    "            average_intersection = (int(average_x), int(average_y))\n",
    "    \n",
    "    return average_intersection\n",
    "\n",
    "# Function to process the image and perform red stop detection\n",
    "def process_stop_sign(image,cropped_image):\n",
    "    # Convert BGR to HSV\n",
    "    hsv_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #ranges for the red color\n",
    "    lower_red1 = np.array([0, 100, 100])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([160, 100, 100])\n",
    "    upper_red2 = np.array([179, 255, 255])\n",
    "    \n",
    "    # Create masks for the red color ranges\n",
    "    mask_red1 = cv2.inRange(hsv_image, lower_red1, upper_red1)\n",
    "    mask_red2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "    \n",
    "    # Combine the masks for the two red ranges\n",
    "    mask_red = cv2.add(mask_red1, mask_red2)\n",
    "    # Find contours for red square\n",
    "    contours_red, _ = cv2.findContours(mask_red, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if (np.array(contours_red, dtype=object).size < 3): ## size 3-5\n",
    "         line_follow(image)\n",
    "    else:\n",
    "        #find the largest contour\n",
    "        largest_contour_red = max(contours_red, key=cv2.contourArea)\n",
    "        M = cv2.moments(largest_contour_red)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(image, (cx, cy), 5, (255, 0, 0), -1)\n",
    "            #if you are very close, stop the robot\n",
    "            if cy > 85:\n",
    "            #stop the robot as you are at stop condition \n",
    "                robot.stop()\n",
    "\n",
    "    red_widget.value = bgr8_to_jpeg(mask_red)\n",
    "    \n",
    "    \n",
    "# Function to process the image and perform green square detection\n",
    "def process_green_square(image,cropped_image):\n",
    "    global turn_time\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds for green color in HSV\n",
    "    lower_green = np.array([35, 100, 25])\n",
    "    upper_green = np.array([90, 255, 255])\n",
    "\n",
    "    # Threshold the image to get only green regions\n",
    "    mask_green = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # Find contours for green square\n",
    "    contours_green, _ = cv2.findContours(mask_green, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if (np.array(contours_green, dtype=object).size < 3): ## size 3-5\n",
    "        process_stop_sign(image,cropped_image)\n",
    "    else:\n",
    "        #find the largest contour \n",
    "        largest_contour_green = max(contours_green, key=cv2.contourArea)\n",
    "        # getting the area for the U turn \n",
    "        total_area=sum(cv2.contourArea(contour) for contour in contours_green)\n",
    "        area_label.value = f'Area: {total_area}'\n",
    "        \n",
    "        M_green = cv2.moments(largest_contour_green)\n",
    "        if M_green[\"m00\"] != 0:\n",
    "            cx_green = int(M_green[\"m10\"] / M_green[\"m00\"])\n",
    "            cy_green = int(M_green[\"m01\"] / M_green[\"m00\"])\n",
    "            \n",
    "            cx_label.value = f'cx: {cx_green}'\n",
    "            cy_label.value = f'cy: {cy_green}'\n",
    "            \n",
    "            cv2.circle(cropped_image, (cx_green, cy_green), 5, (0, 255, 0), -1)\n",
    "            average_x=0\n",
    "            average_y=0\n",
    "            intersection=find_intersection(cropped_image)\n",
    "            if intersection is not None: \n",
    "                average_x, average_y=intersection\n",
    "                cv2.circle(cropped_image, (average_x, average_y), 5, (0, 0, 255), -1)\n",
    "                \n",
    "            average_x_label.value = f'Avg x: {average_x}'\n",
    "            average_y_label.value = f'Avg y: {average_y}'\n",
    "            \n",
    "            #check the turn conditions and make a turn a decision \n",
    "            if (time.time() - turn_time > 0.5) and cy_green> 30 and (intersection is not None) and total_area < 1100: # works for other case \n",
    "                if cx_green > average_x :\n",
    "                    robot.forward(0.1)\n",
    "                    time.sleep(0.4)\n",
    "                    robot.right(0.11)\n",
    "                    time.sleep(0.6)\n",
    "                    robot.forward(0.15)\n",
    "                    time.sleep(0.2)\n",
    "                    turn_time =  time.time()\n",
    "                else:\n",
    "                    robot.forward(0.1)\n",
    "                    time.sleep(0.4)\n",
    "                    robot.left(0.095)\n",
    "                    time.sleep(0.6)\n",
    "                    robot.stop()\n",
    "                    turn_time =  time.time()\n",
    "                    \n",
    "            # Make a U-turn case \n",
    "            elif (time.time() - turn_time > 0.5) and cy_green < 20 and total_area > 1100: # CONFIRM IN THE MORNING theses values -> lighing might impact \n",
    "                robot.forward(0.1)\n",
    "                time.sleep(0.4)\n",
    "                robot.left(0.11)\n",
    "                time.sleep(2.2)\n",
    "                turn_time =  time.time()\n",
    "                \n",
    "            else:\n",
    "                robot.forward(0.09)\n",
    "                time.sleep(0.00001) # to consider \n",
    "                    \n",
    "    green_widget.value = bgr8_to_jpeg(cropped_image)\n",
    "\n",
    "# Line following logic\n",
    "def line_follow(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Manually set the threshold value\n",
    "    manual_threshold_value = 70\n",
    "\n",
    "    # Apply manual thresholding\n",
    "    _, thresholded = cv2.threshold(gray, manual_threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours for line following\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        #find the largest contour \n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        M = cv2.moments(largest_contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            \n",
    "            cv2.circle(image, (cx, cy), 5, (255, 0, 0), -1)\n",
    "            #make a line follow decision \n",
    "            if cx > 50 and cx < 100:\n",
    "                robot.forward(0.12)\n",
    "            elif cx >= 100:\n",
    "                robot.right(0.1)\n",
    "            elif cx <= 50:\n",
    "                robot.left(0.1)\n",
    "            elif cy >150:\n",
    "                robot.forward(0.12)\n",
    "    else:\n",
    "        #if you do not see any black liene contour\n",
    "        robot.forward(0.12)\n",
    "\n",
    "    gray_widget.value = bgr8_to_jpeg(thresholded)\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "\n",
    "# Function to update the image widget\n",
    "def update_image(change):\n",
    "    #print(\"Updating image now\")\n",
    "    image = change['new']\n",
    "    \n",
    "    #crop the image for line following \n",
    "    top_left = (47, 90)  # Example coordinates, adjust as needed\n",
    "    bottom_right = (207, 224) \n",
    "    w = bottom_right[0] - top_left[0]\n",
    "    h = bottom_right[1] - top_left[1]\n",
    "    cropped_image = image[top_left[1]:top_left[1] + h, top_left[0]:top_left[0] + w]\n",
    "    \n",
    "    #crop the image for green detection and red stop sign \n",
    "    top_left_main = (39,30)\n",
    "    bottom_right_main = (194,210)\n",
    "    w_main = bottom_right_main[0] - top_left_main[0]\n",
    "    h_main = bottom_right_main[1] - top_left_main[1]\n",
    "    main_image = image[top_left_main[1]:top_left_main[1] + h_main, top_left_main[0]:top_left_main[0] + w_main]\n",
    "    \n",
    "    process_green_square(main_image,cropped_image)\n",
    "\n",
    "\n",
    "# Attach the update function to the camera\n",
    "camera.observe(update_image, names='value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop the camera observe process and stop running the robot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update_image, names='value')\n",
    "\n",
    "time.sleep(4.0)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://towardsdatascience.com/getting-started-in-ai-and-computer-vision-with-nvidia-jetson-nano-df2cacbd291c\n",
    "* https://www.inspiritai.com/blogs/ai-blog/2021/8/31/student-blog-project-bridging-ai-and-robotics\n",
    "* https://github.com/thehapyone/Platooning-Robot/blob/master/Robot/Main/Lane%20Detection/lane_detect1.py\n",
    "* https://const-toporov.medium.com/line-following-robot-with-opencv-and-contour-based-approach-417b90f2c298\n",
    "* https://rubikscode.net/2022/06/13/thresholding-edge-contour-and-line-detection-with-opencv/\n",
    "* https://resources.altium.com/p/lane-recognition-and-tracking-nvidia-jetson-nano\n",
    "* https://github.com/chrisdalke/ros-line-follower-robot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
